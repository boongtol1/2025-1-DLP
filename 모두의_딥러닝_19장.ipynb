{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19장 세상에 없는 얼굴 GAN, 오토인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/taehojo/taehojo.github.io/master/assets/images/linktocolab.png\" align=\"left\"/> ](https://colab.research.google.com/github/taehojo/deeplearning/blob/master/colab/ch19-colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 적대적 신경망 실행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습: GAN 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 예제 파일에서 data 폴더 아래에 이미지가 저장될 gan_images 폴더가 함께 제공됩니다.\n",
    "# 만약 이미지가 저장될 폴더가 없다면 아래 코드의 주석을 해제해 gan_images 폴더를 만듭니다.\n",
    "# import os\n",
    "# if not os.path.exists(\"./data/gan_images\"):\n",
    "#    os.makedirs(\"./data/gan_images\")\n",
    "# 랜덤한 노이즈는 ‘아무 의미 없는 숫자들의 벡터’예요.\n",
    "# 생성자 모델을 만듭니다.\n",
    "\n",
    "# Sequential 모델은 각 층의 출력이 자동으로 다음 층의 입력이 되도록 순차적으로 연결하는 구조입니다.\n",
    "# Dense 층은 입력 값 하나하나를 전부 출력 뉴런과 연결해서, 가중치로 계산하고 새로운 정보를 만들어내는 층이에요.\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))  # 여기서 텐서의 합성곱 개념이 쓰인다!(한경훈 교수님 강의 보기!) // 각 채널마다 다른 5×5 행렬을 쓰는 이유는, 채널마다 감지할 정보가 다르기 때문입니다.\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D()) \n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "\n",
    "# 판별자 모델을 만듭니다.\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False   # 진짜/가짜를 구분하는게 곧 이진 분류와 비슷하다는것!\n",
    "\n",
    "# 생성자와 판별자 모델을 연결시키는 gan 모델을 만듭니다.\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()\n",
    "\n",
    "# 신경망을 실행시키는 함수를 만듭니다.\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "\n",
    "  # MNIST 데이터를 불러옵니다.\n",
    "\n",
    "  (X_train, _), (_, _) = mnist.load_data()  # 앞서 불러온 적 있는 MNIST를 다시 이용합니다. 단, 테스트 과정은 필요 없고 이미지만 사용할 것이기 때문에 X_train만 불러왔습니다.\n",
    "  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_train = (X_train - 127.5) / 127.5  # 픽셀 값은 0에서 255 사이의 값입니다. 이전에 255로 나누어 줄때는 이를 0~1 사이의 값으로 바꾸었던 것인데, 여기서는 127.5를 빼준 뒤 127.5로 나누어 줌으로 인해 -1에서 1사이의 값으로 바뀌게 됩니다.\n",
    "  # X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "  true = np.ones((batch_size, 1)) # batch_size의 행 , 1개의 열!\n",
    "  fake = np.zeros((batch_size, 1))\n",
    "\n",
    "  for i in range(epoch):\n",
    "          # 실제 데이터를 판별자에 입력하는 부분입니다.\n",
    "          idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "          imgs = X_train[idx] # imgs.shape = (32, 28, 28, 1)!\n",
    "          d_loss_real = discriminator.train_on_batch(imgs, true)  # 진짜 이미지를 Discriminator에 입력하고, 정답 라벨 1(진짜)을 이용해 학습시킨 다음,손실값(loss)을 계산해서 반환하는 과정입니다. // 진짜 이미지(real)를 가지고 Discriminator를 훈련하는 부분입니다.\n",
    "\n",
    "\n",
    "\n",
    "          # 가상 이미지를 판별자에 입력하는 부분입니다.\n",
    "          noise = np.random.normal(0, 1, (batch_size, 100)) # noise 의 shape = (32, 100) 입니다. 100은 앞서 생성자 모델을 만들 때 입력으로 넣었던 벡터의 크기입니다.  / 0,1 은 각각 평균과 표준편차!\n",
    "          gen_imgs = generator.predict(noise)\n",
    "          d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)    # GAN 훈련 과정 중에서 \"Discriminator에게 가짜 이미지를 보여주고 훈련시키는 부분\n",
    "\n",
    "          # 판별자와 생성자의 오차를 계산합니다.\n",
    "          d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "          g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "          print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "        # 이 부분은 중간 과정을 이미지로 저장해 주는 부분입니다. 본 장의 주요 내용과 관련이 없어\n",
    "        # 소스 코드만 첨부합니다. 만들어진 이미지들은 gan_images 폴더에 저장됩니다.\n",
    "          if i % saving_interval == 0:\n",
    "              #r, c = 5, 5\n",
    "              noise = np.random.normal(0, 1, (25, 100))\n",
    "              gen_imgs = generator.predict(noise)\n",
    "\n",
    "              # Rescale images 0 - 1\n",
    "              gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "              fig, axs = plt.subplots(5, 5)\n",
    "              count = 0\n",
    "              for j in range(5):\n",
    "                  for k in range(5):\n",
    "                      axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                      axs[j, k].axis('off')\n",
    "                      count += 1\n",
    "              fig.savefig(\"./data/gan_images/gan_mnist_%d.png\" % i)\n",
    "\n",
    "gan_train(10001, 32, 200)  # 2000번 반복되고, 배치 사이즈는 32,  200번마다 결과가 저장되게 하였습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 이미지의 특징을 추출하는 오토인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습: 오토인코더 실습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# MNIST 데이터셋을 불러옵니다.\n",
    "\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# 생성자 모델을 만듭니다.\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# 인코딩 부분입니다.\n",
    "autoencoder.add(Conv2D(16, kernel_size=3, padding='same', input_shape=(28,28,1), activation='relu'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "\n",
    "# 디코딩 부분이 이어집니다. \n",
    "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(1, kernel_size=3, padding='same', activation='sigmoid'))\n",
    "\n",
    "# 전체 구조를 확인해 봅니다.\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컴파일 및 학습을 하는 부분입니다.\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test))\n",
    "\n",
    "# 학습된 결과를 출력하는 부분입니다.\n",
    "random_test = np.random.randint(X_test.shape[0], size=5)  # 테스트할 이미지를 랜덤하게 불러옵니다.\n",
    "ae_imgs = autoencoder.predict(X_test)                     # 앞서 만든 오토인코더 모델에 집어 넣습니다.\n",
    "\n",
    "plt.figure(figsize=(7, 2))                         # 출력될 이미지의 크기를 정합니다.\n",
    "\n",
    "for i, image_idx in enumerate(random_test):       # 랜덤하게 뽑은 이미지를 차례로 나열합니다.\n",
    "   ax = plt.subplot(2, 7, i + 1) \n",
    "   plt.imshow(X_test[image_idx].reshape(28, 28))   # 테스트할 이미지를 먼저 그대로 보여줍니다.\n",
    "   ax.axis('off')\n",
    "   ax = plt.subplot(2, 7, 7 + i +1)\n",
    "   plt.imshow(ae_imgs[image_idx].reshape(28, 28)) # 오토인코딩 결과를 다음열에 출력합니다.\n",
    "   ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
